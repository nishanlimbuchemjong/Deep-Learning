{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b8fe551-f90c-4702-a15f-2423951985e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b95aecef-16fb-49e7-894c-ffcbf3c62439",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da5c3b4e-cb4b-4508-857c-047a65164f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98a4e62d-45d6-4df0-ab4c-5efb23e20c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39e7dabc-e657-4448-81c3-e1401cef4cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Dense(64, activation='relu'))\n",
    "cnn.add(Dense(34, activation='relu'))\n",
    "cnn.add(Dense(16, activation='relu'))\n",
    "cnn.add(Dense(8, activation='relu'))\n",
    "cnn.add(Dense(4, activation='relu'))\n",
    "cnn.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1f16592-83d1-4057-9974-be4ca2e4c93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comple cnn model\n",
    "cnn.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f99027d-4dee-41d2-85e4-8a6de055311d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n",
      "Epoch 1/5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 6s/step - loss: 0.6932 - val_loss: 0.6932\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\venv\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - loss: 0.6932 - val_loss: 0.6931\n",
      "Epoch 3/5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2s/step - loss: 0.6929 - val_loss: 0.6932\n",
      "Epoch 4/5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - loss: 0.6928 - val_loss: 0.6932\n",
      "Epoch 5/5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2s/step - loss: 0.6931 - val_loss: 0.6932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x224a81b90d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting datas from directory; image preprocessing from kearas:\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        r'./dataset/train',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        r'./dataset/test',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "cnn.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=20,\n",
    "        epochs=5,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7000460e-b0da-425f-b4b4-4371f2db22c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c25408-5b50-491a-9b9a-ebaf4b416602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c75588-8efb-4c66-855f-26ff1fd801a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcdaadac-5e31-40f5-9b54-c994b9d6be23",
   "metadata": {},
   "source": [
    "# For New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95b9e29f-7fee-4363-8ace-3124aa4a887c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "67963f2c-4ed4-4568-8c27-f871113bcf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(r'./dataset/testing_dataset/dog.jpg', target_size=(64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6519a4da-8ff2-49ac-af0c-d5b94ae6b25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting image into array\n",
    "img = image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0ea4bc5b-c849-424b-ac1a-ef78cee1a9ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[235., 235., 235.],\n",
       "        [236., 236., 236.],\n",
       "        [245., 245., 245.],\n",
       "        ...,\n",
       "        [246., 246., 246.],\n",
       "        [241., 241., 241.],\n",
       "        [244., 244., 244.]],\n",
       "\n",
       "       [[241., 241., 241.],\n",
       "        [237., 237., 237.],\n",
       "        [238., 238., 238.],\n",
       "        ...,\n",
       "        [242., 242., 242.],\n",
       "        [248., 248., 248.],\n",
       "        [242., 242., 242.]],\n",
       "\n",
       "       [[237., 237., 237.],\n",
       "        [239., 239., 239.],\n",
       "        [238., 238., 238.],\n",
       "        ...,\n",
       "        [244., 244., 244.],\n",
       "        [236., 236., 236.],\n",
       "        [234., 234., 234.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[213., 213., 213.],\n",
       "        [208., 208., 208.],\n",
       "        [203., 203., 203.],\n",
       "        ...,\n",
       "        [ 80.,  80.,  80.],\n",
       "        [ 53.,  53.,  53.],\n",
       "        [ 58.,  58.,  58.]],\n",
       "\n",
       "       [[209., 209., 209.],\n",
       "        [204., 204., 204.],\n",
       "        [193., 193., 193.],\n",
       "        ...,\n",
       "        [ 77.,  77.,  77.],\n",
       "        [ 61.,  61.,  61.],\n",
       "        [ 53.,  53.,  53.]],\n",
       "\n",
       "       [[194., 194., 194.],\n",
       "        [208., 208., 208.],\n",
       "        [208., 208., 208.],\n",
       "        ...,\n",
       "        [ 64.,  64.,  64.],\n",
       "        [ 42.,  42.,  42.],\n",
       "        [ 65.,  65.,  65.]]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6f112c89-c87d-4ff9-a6b7-fbe2eeba187b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn cannot be used directly. so we need to flatten\n",
    "img = np.expand_dims(img, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4f69cf7e-8a68-446c-bbb8-69ed8a029249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n"
     ]
    }
   ],
   "source": [
    "# uing prediction\n",
    "res = cnn.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f5458fa9-3fd5-466c-981c-ddb269e2c32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is a Dog\n"
     ]
    }
   ],
   "source": [
    "if res[0][0] < 0.5:\n",
    "    print(\"It is a Dog\")\n",
    "    \n",
    "else:\n",
    "    print(\"It is a Dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e717f7-263c-4b27-a340-15b9424c9a26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bebe16-2578-42cb-b02e-7699b7853b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
